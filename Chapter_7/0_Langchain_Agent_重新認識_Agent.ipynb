{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "B6F1Jrg9TdXp",
        "MFVkNNMDS3yt",
        "lK4N2EgPUaSG",
        "GErPnLAWRXfy",
        "XHlRgvQIXGE_"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 重新認識認識 Agent\n",
        "\n",
        "Agent 是一個推理引擎，旨在做出決策、選擇工具並採取行動以實現特定的、通常是預定義的目標或一組目標。Agent 自主運行，很少需要人工干預其操作。\n",
        "正是正確的強大工具以及自力更生，目前使 Agent 吸引了如此多的注意力。它們當然是我們的未來，值得熟悉這項技術。\n",
        "\n",
        "本章節中，將帶領各位學員，如何熟練掌握 Agent 使用技巧與知識\n",
        "\n",
        "* Agent 基礎認識\n",
        "* Agent 多種 Type 介紹，如：ReAct、zero shot\n",
        "* 客製化 Agent\n",
        "* 客製化 Tool\n",
        "* 分享多個有趣案例\n",
        "\n",
        "官網連結: [Agent](https://python.langchain.com/en/latest/modules/agents.html)\n",
        "\n",
        "![Qoo](https://imgur.com/VxVFEUl.png)"
      ],
      "metadata": {
        "id": "fWA2xw8Vv6PF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 建立環境與設置參數"
      ],
      "metadata": {
        "id": "B6F1Jrg9TdXp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 安裝套件包"
      ],
      "metadata": {
        "id": "pyMKmLv_v8gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install requests\n",
        "!pip install duckduckgo-search\n",
        "!pip install wikipedia"
      ],
      "metadata": {
        "id": "w_LbVgMns0bi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36f6ec31-f685-4ab8-e031-9aaa5259558c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.193-py3-none-any.whl (989 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.0/990.0 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.10)\n",
            "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
            "Collecting langchainplus-sdk<0.0.5,>=0.0.4 (from langchain)\n",
            "  Downloading langchainplus_sdk-0.0.4-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting typing-inspect>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, multidict, marshmallow, frozenlist, async-timeout, yarl, typing-inspect, openapi-schema-pydantic, marshmallow-enum, langchainplus-sdk, aiosignal, dataclasses-json, aiohttp, langchain\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 dataclasses-json-0.5.7 frozenlist-1.3.3 langchain-0.0.193 langchainplus-sdk-0.0.4 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 typing-inspect-0.9.0 yarl-1.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting duckduckgo-search\n",
            "  Downloading duckduckgo_search-3.8.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (8.1.3)\n",
            "Requirement already satisfied: lxml>=4.9.2 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (4.9.2)\n",
            "Collecting httpx[brotli,http2,socks]>=0.24.1 (from duckduckgo-search)\n",
            "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx[brotli,http2,socks]>=0.24.1->duckduckgo-search) (2022.12.7)\n",
            "Collecting httpcore<0.18.0,>=0.15.0 (from httpx[brotli,http2,socks]>=0.24.1->duckduckgo-search)\n",
            "  Downloading httpcore-0.17.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx[brotli,http2,socks]>=0.24.1->duckduckgo-search) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx[brotli,http2,socks]>=0.24.1->duckduckgo-search) (1.3.0)\n",
            "Collecting h2<5,>=3 (from httpx[brotli,http2,socks]>=0.24.1->duckduckgo-search)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotli (from httpx[brotli,http2,socks]>=0.24.1->duckduckgo-search)\n",
            "  Downloading Brotli-1.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting socksio==1.* (from httpx[brotli,http2,socks]>=0.24.1->duckduckgo-search)\n",
            "  Downloading socksio-1.0.0-py3-none-any.whl (12 kB)\n",
            "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[brotli,http2,socks]>=0.24.1->duckduckgo-search)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[brotli,http2,socks]>=0.24.1->duckduckgo-search)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore<0.18.0,>=0.15.0->httpx[brotli,http2,socks]>=0.24.1->duckduckgo-search)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx[brotli,http2,socks]>=0.24.1->duckduckgo-search) (3.6.2)\n",
            "Installing collected packages: brotli, socksio, hyperframe, hpack, h11, httpcore, h2, httpx, duckduckgo-search\n",
            "Successfully installed brotli-1.0.9 duckduckgo-search-3.8.1 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-0.17.2 httpx-0.24.1 hyperframe-6.0.1 socksio-1.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.11.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.4.1)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11680 sha256=de75d0d0c4f0b8001de86465726fd2f11e7fced174d6e15d0c2522cd87236542\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 設定專案 Log 資訊\n"
      ],
      "metadata": {
        "id": "UJzju4jwtAF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
      ],
      "metadata": {
        "id": "8_FsneZ6s_n_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 環境參數建置"
      ],
      "metadata": {
        "id": "z6lKpjqzUOez"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Qop_upesuRa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OPENAI 環節"
      ],
      "metadata": {
        "id": "XiiKa-LbR4PJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
        "  os.environ[\"OPENAI_API_KEY\"] = getpass(\"可以從以下網站找到 Api-key: https://platform.openai.com/account/api-keys\\n\")\n",
        "assert os.getenv(\"OPENAI_API_KEY\", \"\").startswith(\"sk-\"), \"貌似不是合理的 OpenAI API key\"\n",
        "print(\"OpenAI API key configured\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_Ls-4mPR7Uj",
        "outputId": "9e087b1c-0bf9-4a56-a7b2-ca93eb1b1b0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "可以從以下網站找到 Api-key: https://platform.openai.com/account/api-keys\n",
            "··········\n",
            "OpenAI API key configured\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### WA_環節\n"
      ],
      "metadata": {
        "id": "9akEe467Fl6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if os.getenv(\"WA_API_KEY\") is None:\n",
        "  os.environ[\"WA_API_KEY\"] = getpass(\"可以從以下網站找到 Api-key: https://www.wolframalpha.com/\\n\")\n",
        "print(\"WA API key configured\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMKKSjrrFqvx",
        "outputId": "3d3c1891-0742-428a-a96b-c5d95ab6adf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "可以從以下網站找到 Api-key: https://www.wolframalpha.com/\n",
            "··········\n",
            "WA API key configured\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 初步操作 Agent\n",
        "\n"
      ],
      "metadata": {
        "id": "qmBF3f0dfqQF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 暖暖手 - 建構簡單 LLM Chain"
      ],
      "metadata": {
        "id": "xAvqzlzbgdme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Initiate our LLM - default is 'gpt-3.5-turbo'\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "#\n",
        "prompt = PromptTemplate(\n",
        "  input_variables=[\"query\"],\n",
        "  template=\"You are New Native Internal Bot. Help users with their important tasks, like a professor in a particular field. Query: {query}\"\n",
        ")\n",
        "\n",
        "#\n",
        "llm_chain = LLMChain(llm=llm, prompt=prompt)"
      ],
      "metadata": {
        "id": "SWcyklDYf86R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 測試 Chain 效果"
      ],
      "metadata": {
        "id": "N13O1AaqgfZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain.run(\"what is (4.5*2.1)^2.2?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "z9f7Ad4xgi7j",
        "outputId": "1a0e851f-bb18-4dda-c266-556efdbdf40e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The answer to the query \"what is (4.5*2.1)^2.2?\" is approximately 174.9.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 替 Agent 增加聯外工具"
      ],
      "metadata": {
        "id": "Wa6fzlDLEiJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import DuckDuckGoSearchRun\n",
        "from langchain.agents import Tool\n",
        "\n",
        "search = DuckDuckGoSearchRun()\n",
        "\n",
        "# Web Search Tool\n",
        "search_tool = Tool(\n",
        "    name = \"Web Search\",\n",
        "    func=search.run,\n",
        "    description=\"A useful tool for searching the Internet to find information on world events, issues, etc. Worth using for general topics. Use precise questions.\"\n",
        ")"
      ],
      "metadata": {
        "id": "KXaammkqFZZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "class WA:\n",
        "  \"\"\"\n",
        "    Wolfram|Alpha API\n",
        "  \"\"\"\n",
        "  def __init__(self, app_id):\n",
        "    self.url = f\"http://api.wolframalpha.com/v1/result?appid={app_id}&i=\"\n",
        "\n",
        "  def run(self, query):\n",
        "    query = query.replace(\"+\", \" plus \").replace(\"-\", \" minus \") # '+' and '-' are used in URI and cannot be used in request\n",
        "    result = requests.post(f\"{self.url}{query}\")\n",
        "\n",
        "    if not result.ok:\n",
        "      raise Exception(\"Cannot call WA API.\")\n",
        "\n",
        "    return result.text"
      ],
      "metadata": {
        "id": "HfazbW-YgkvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wa = WA(app_id=os.environ[\"WA_API_KEY\"])\n",
        "\n",
        "wa_tool = Tool(\n",
        "    name=\"Wolfram|Alpha API\",\n",
        "    func=wa.run,\n",
        "    description=\"Wolfram|Alpha API. It's super powerful Math tool. Use it for simple & complex math tasks.\"\n",
        ")"
      ],
      "metadata": {
        "id": "RH6QusazFg6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 建立 Agent 並測試聯外工具"
      ],
      "metadata": {
        "id": "DtUrIHAMF-A-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType\n",
        "\n",
        "agent = initialize_agent(\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    tools=[wa_tool, search_tool],\n",
        "    llm=llm,\n",
        "    verbose=True, # I will use verbose=True to check process of choosing tool by Agent\n",
        "    max_iterations=3\n",
        ")"
      ],
      "metadata": {
        "id": "uRBuytv2F8qN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent(\"what is (4.5*2.1)^2.2?\")\n",
        "print(f\"Final answer: {response['output']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DCRWUKpGH2N",
        "outputId": "d8acf479-629f-4224-889b-0689e519cb96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThis is a complex math problem, so I should use the Wolfram|Alpha API.\n",
            "Action: Wolfram|Alpha API\n",
            "Action Input: (4.5*2.1)^2.2\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m139.943\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: 139.943\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Final answer: 139.943\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 慢著，Agent 與 Chain 有何不同？\n",
        "\n",
        "如果我們查看 Agent 的邏輯和剛剛 printout 的提示，我們將看到一些明顯的差異。首先，我們有提示中包含的工具。其次，我們有一個思維過程，以前是即時的 Chain，但現在涉及“Though”，“Action”，“Action input”，“Obervation”。這到底是怎麼回事？\n",
        "\n",
        "現在只要說LLM現在有能力“推理”如何最好地使用工具來解決我們的查詢，並且可以以智慧的方式將它們組合在一起，只需對每個工具進行簡要描述。如果您想詳細瞭解此範例 （MRKL），請[參閱本文](https://arxiv.org/pdf/2205.00445.pdf)。\n",
        "\n",
        "這就是我們將附加代理已經執行的每個想法或操作的地方。這樣，在每個時間點，智慧體都會知道它發現了什麼，並能夠繼續其思維過程。換句話說，在使用工具后，它會將其想法和觀察添加到暫存器中，並從那裡拾取。\n",
        "\n",
        "![link text](https://imgur.com/eDiWmja.jpg)"
      ],
      "metadata": {
        "id": "maWvsGq7PkSI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent Types 認識\n",
        "\n",
        "在本節中，我們將回顧幾個 Agent，看看他們如何“思考”以及他們可以做什麼。\n",
        "\n",
        "使用langchain的 Agent 中涉及三個變數：\n",
        "\n",
        "* 定義工具(tool)\n",
        "* 定義大型語言模型(LLM)\n",
        "* 定義Agent 種類 (Agent Type)\n",
        "\n",
        "這在langchain中非常容易做到，正如我們將在下面的範例中看到的那樣。\n",
        "\n",
        "LangChain [多種 Type 介紹](https://python.langchain.com/en/latest/modules/agents/agents/agent_types.html)\n",
        "\n",
        "Langchain [github Type](https://github.com/hwchase17/langchain/blob/d9fcc45d057e3c8148dc82efd1150c383fcb245e/langchain/agents/agent_types.py#L4)"
      ],
      "metadata": {
        "id": "U5LZGP5MLS7L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###認識 Agent 種類 - Agnet Type #1: Zero Shot React\n",
        "\n",
        "我們首先需要初始化我們將在本例中使用的工具。在這裡，我們希望我們的代理做數學，所以我們將使用“llm-math”，這是我們解決數學問題的工具。這是我們可以使用 load_tools 實用程式載入的幾個工具之一 - 您可以通過查看文件來查看更多資訊。\n",
        "\n",
        "LangChain 官方連結：[Agent_type](https://python.langchain.com/en/latest/modules/agents/agents/agent_types.html)"
      ],
      "metadata": {
        "id": "DylT-NgmMIWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools\n",
        "\n",
        "tools = load_tools(\n",
        "    [\"llm-math\"],\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "zero_shot_react_agent = initialize_agent(\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    verbose=True, # I will use verbose=True to check process of choosing tool by Agent\n",
        "    max_iterations=3\n",
        ")\n",
        "\n",
        "response = zero_shot_react_agent(\"what is (4.5*2.1)^2.2?\")\n",
        "print(f\"Final answer: {response['output']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9gZ95n2LVl5",
        "outputId": "f6a137d6-5498-494c-ae86-8a20b77f32f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to use the calculator to solve this problem.\n",
            "Action: Calculator\n",
            "Action Input: (4.5*2.1)^2.2\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAnswer: 139.94261298333066\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
            "Final Answer: 139.94261298333066\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Final answer: 139.94261298333066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 顯示查看 Agent 使用的 Prompt"
      ],
      "metadata": {
        "id": "UodTJ1ilPGwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(zero_shot_react_agent.agent.llm_chain.prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKYzayAwOlo7",
        "outputId": "9cbfb3c4-bd68-429a-d930-d79104ade7f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer the following questions as best you can. You have access to the following tools:\n",
            "\n",
            "Calculator: Useful for when you need to answer questions about math.\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [Calculator]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "\n",
            "Question: {input}\n",
            "Thought:{agent_scratchpad}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###認識 Agent 種類 - Agent Type #2: Chat Conversational ReAct\n",
        "\n",
        "前面章節當中，我們已經認識到 Zerp Shot Agent，是挺有趣的，但是該 Agent 本質為 Stateless，缺乏記憶的。我們常用的場景中是希望這名聊天對象記得我們的談話，為此該怎麼做呢？我們需要使用 conversational react agemt"
      ],
      "metadata": {
        "id": "R49_9a_YVpmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools\n",
        "\n",
        "tools = load_tools(\n",
        "    [\"llm-math\"],\n",
        "    llm=llm\n",
        ")"
      ],
      "metadata": {
        "id": "MSO_KsKwPNyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 添加記憶\n",
        "\n",
        "添加 Memory 的方式就很多了，Langchain 就提供以下幾種\n",
        "\n",
        "* ConversationBufferMemory 暫存對話\n",
        "* ConversationBufferWindowMemory 保留一段對話的暫存對話\n",
        "* MongoDBChatMessageHistory 使用 MangoDB 紀錄對話資訊"
      ],
      "metadata": {
        "id": "kKy_JpXMWq9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "\n",
        "conversation_memory = ConversationBufferWindowMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    k=5,\n",
        "    return_messages=True\n",
        ")\n",
        "\n",
        "conversational_agent = initialize_agent(\n",
        "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    max_iterations=3,\n",
        "    memory=conversation_memory,\n",
        ")"
      ],
      "metadata": {
        "id": "mloZlOWfWuFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = conversational_agent(\"what is (4.5*2.1)^2.2?\")\n",
        "print(f\"Final answer: {response['output']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZGspN4-XOGe",
        "outputId": "91254212-afa5-4bf2-e03f-5dc6c84fddc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m{\n",
            "    \"action\": \"Final Answer\",\n",
            "    \"action_input\": \"139.94261298333066\"\n",
            "}\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Final answer: 139.94261298333066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 顯示查看 Agent 使用的 Prompt"
      ],
      "metadata": {
        "id": "io20uHJIX2m6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(conversational_agent.agent.llm_chain.prompt.messages[0].prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-NlS8sXXSOq",
        "outputId": "4f75e310-a96a-435a-c753-ae8d9e921d4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assistant is a large language model trained by OpenAI.\n",
            "\n",
            "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, Assistant is a powerful system that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[點我查看更多內容資訊](https://arxiv.org/pdf/2210.03629.pdf)"
      ],
      "metadata": {
        "id": "UwJDUOcMdBCG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 認識 Agent 種類 - Agent Type #3: ReAct DocStore\n",
        "\n",
        "這種類型的代理類似於我們目前看到的代理，但它包括與文檔存儲的交互。它將有兩個且只有兩個工具可供使用：「Search」和「lookup」。\n",
        "\n",
        "使用 search ，它將調出相關文章，使用 lookup， Agent 將在文章中找到正確的資訊。這可能在示例中最容易看到："
      ],
      "metadata": {
        "id": "3ufOdy2zaYZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import Wikipedia\n",
        "from langchain.agents.react.base import DocstoreExplorer\n",
        "\n",
        "docstore=DocstoreExplorer(Wikipedia())\n",
        "\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Search\",\n",
        "        func=docstore.search,\n",
        "        description='search wikipedia'\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Lookup\",\n",
        "        func=docstore.lookup,\n",
        "        description='lookup a term in wikipedia'\n",
        "    )\n",
        "]\n",
        "\n",
        "conversation_memory = ConversationBufferWindowMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    k=5,\n",
        "    return_messages=True\n",
        ")\n",
        "\n",
        "docstore_agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.REACT_DOCSTORE,\n",
        "    verbose=True,\n",
        "    max_iterations=3,\n",
        "    memory=conversation_memory\n",
        ")"
      ],
      "metadata": {
        "id": "R_a-eczTaj8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = docstore_agent(\"What were Archimedes' last words?\")\n",
        "print(f\"Final answer: {response['output']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClUaOC5qalqb",
        "outputId": "243c4cd5-55cf-409d-913f-3223e5f661c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to search for Archimedes' last words and find out what they were.\n",
            "Action: Search[Archimedes' last words]\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mA person's last words, their final articulated words stated prior to death or as death approaches, are often recorded because of the decedent's fame, but sometimes because of interest in the statement itself. (People dying of illness are frequently inarticulate at the end, and in such cases their actual last utterances may not be recorded or considered very important.) Last words may be recorded accurately, or, for a variety of reasons, may not. Reasons can include simple error or deliberate intent. Even if reported wrongly, putative last words can constitute an important part of the perceived historical records or demonstration of cultural attitudes toward death at the time.Charles Darwin, for example, was reported to have disavowed his theory of evolution in favor of traditional religious faith at his death. This widely disseminated report served the interests of those who opposed Darwin's theory on religious grounds. However, the putative witness had not been at Darwin's deathbed or seen him at any time near the end of his life.Both Eastern and Western cultural traditions ascribe special significance to words uttered at or near death, but the form and content of reported last words may depend on cultural context. There is a tradition in Hindu and Buddhist cultures of an expectation of a meaningful farewell statement; Zen monks by long custom are expected to compose a poem on the spot and recite it with their last breath. In Western culture particular attention has been paid to last words which demonstrate deathbed salvation – the repentance of sins and affirmation of faith.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe search did not provide an answer to the question. I need to search specifically for Archimedes' last words.\n",
            "Action: Search[Archimedes' last words specifically]\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAcorn Archimedes is a family of personal computers designed by Acorn Computers of Cambridge, England. The systems are based on Acorn's own ARM architecture processors and the proprietary operating systems Arthur and RISC OS. The first models were introduced in 1987, and systems in the Archimedes family were sold until the mid-1990s.\n",
            "ARM's RISC design, a 32-bit CPU (using 26-bit addressing), running at 8 MHz, was stated as achieving 4 MIPS, which provided a significant upgrade from 8-bit home computers, such as Acorn's previous machines. Claims of being the fastest micro in the world and running at 18 MIPS were also made during tests.Two of the first models—the A305 and A310—were given the BBC branding, with BBC Enterprises regarding the machines as \"a continuing part of the original computer literacy project\". Dissatisfaction with the branding arrangement was voiced by competitor Research Machines and an industry group led by a Microsoft representative, the British Micro Federation, who advocated the use of \"business standard\" operating systems such as MS-DOS. Responding to claims that the BBC branding was \"unethical\" and \"damaging\", a BBC Enterprises representative claimed that, with regard to the BBC's ongoing computer literacy initiatives, bringing in \"something totally new would be irresponsible\".The name \"Acorn Archimedes\" is commonly used to describe any of Acorn's contemporary designs based on the same architecture. This architecture can be broadly characterised as involving the ARM CPU and the first generation chipset consisting of MEMC (MEMory Controller), VIDC (VIDeo and sound Controller) and IOC (Input Output Controller).\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThe search did not provide an answer to the question. I need to search specifically for Archimedes' last words. \n",
            "Action: Search[Archimedes' last words specifically]\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAcorn Archimedes is a family of personal computers designed by Acorn Computers of Cambridge, England. The systems are based on Acorn's own ARM architecture processors and the proprietary operating systems Arthur and RISC OS. The first models were introduced in 1987, and systems in the Archimedes family were sold until the mid-1990s.\n",
            "ARM's RISC design, a 32-bit CPU (using 26-bit addressing), running at 8 MHz, was stated as achieving 4 MIPS, which provided a significant upgrade from 8-bit home computers, such as Acorn's previous machines. Claims of being the fastest micro in the world and running at 18 MIPS were also made during tests.Two of the first models—the A305 and A310—were given the BBC branding, with BBC Enterprises regarding the machines as \"a continuing part of the original computer literacy project\". Dissatisfaction with the branding arrangement was voiced by competitor Research Machines and an industry group led by a Microsoft representative, the British Micro Federation, who advocated the use of \"business standard\" operating systems such as MS-DOS. Responding to claims that the BBC branding was \"unethical\" and \"damaging\", a BBC Enterprises representative claimed that, with regard to the BBC's ongoing computer literacy initiatives, bringing in \"something totally new would be irresponsible\".The name \"Acorn Archimedes\" is commonly used to describe any of Acorn's contemporary designs based on the same architecture. This architecture can be broadly characterised as involving the ARM CPU and the first generation chipset consisting of MEMC (MEMory Controller), VIDC (VIDeo and sound Controller) and IOC (Input Output Controller).\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Final answer: Agent stopped due to iteration limit or time limit.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 總結\n",
        "\n",
        "目前為止學習到在 LangChain 當中多種 Agent Type 並且了改每一種思維模式，接下來我們將讓 Agent 更加聰明些，目標如下\n",
        "\n",
        "* 新增 tool\n",
        "* 新增 agent"
      ],
      "metadata": {
        "id": "rfqMsUx7bgwO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gBzszn14a5pY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}