{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain 快速入門 - 五個必須得知道的知識\n",
        "\n",
        "本章節將向學員展示如何使用 LangChain 建立大型語言模型應用程式\n",
        "\n",
        "官方教學連結：[Module](https://python.langchain.com/en/latest/index.html)"
      ],
      "metadata": {
        "id": "1mPx6qM3w-9T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 套件安裝與環境建置\n"
      ],
      "metadata": {
        "id": "p8u-bI8F2ri1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 安裝\n",
        "\n",
        "在開始之前，需要先安裝兩個套件，分別為 LangChain 以及 OpenAI。\n",
        "\n",
        "* LangChain 通常需要將一個或多個模型、向量資料庫、API 等進行整合。\n",
        "* OpenAI 用於使用 embedding 以及 LLM"
      ],
      "metadata": {
        "id": "ZsBDRcdAyBrx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaqYb9_0wvol",
        "outputId": "abe8a764-8ae3-4016-88a8-045ea7e6bec0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.155-py3-none-any.whl (727 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.0/727.0 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.10)\n",
            "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.65.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting typing-inspect>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.3->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, multidict, marshmallow, frozenlist, async-timeout, yarl, typing-inspect, openapi-schema-pydantic, marshmallow-enum, aiosignal, dataclasses-json, aiohttp, langchain\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 dataclasses-json-0.5.7 frozenlist-1.3.3 langchain-0.0.155 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 typing-inspect-0.8.0 yarl-1.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.6\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 環境參數設置\n",
        "\n",
        "本章節中，將會使用到 OpenAI API key。"
      ],
      "metadata": {
        "id": "rN3M0IBGzFxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-xxx\" # 會是 sk-XXXX 樣式的字樣"
      ],
      "metadata": {
        "id": "zB4BUkiHxA2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 建構大型語言模型應用，簡稱「打造 AI APPS」\n",
        "\n",
        "現在，我們已經安裝了LangChain並設置了環境，可以開始構建我們的大型語言模型應用程式。\n",
        "\n",
        "LangChain提供了許多模組，可用於構建語言模型應用程式。這些模組可以組合在一起創建更複雜的應用程式，或者單獨用於簡單的應用程式。\n",
        "\n",
        "本課程當中，會帶領大家熟練操作以下元素：\n",
        "\n",
        "* [Model](https://python.langchain.com/en/latest/modules/models.html): 為 Langchain 當中支持的各種大型語言模型，如：OpenAI、HuggingFace、cohere 等。\n",
        "* [Prompt](https://python.langchain.com/en/latest/modules/prompts.html): 進行 Prompt 管理，序列化。\n",
        "* [chain](https://python.langchain.com/en/latest/modules/chains.html): LangChain 為 Chain 提供標準接口、與其他工具的大量集成以及用於常見應用程序的端到端鏈。\n",
        "* [Agent](https://python.langchain.com/en/latest/modules/agents.html): LangChain 為 Agent 提供了一個標準接口，可供選擇的代理選擇，以及端到端代理的示例。例如：\"zero-shot-description\" 等\n",
        "* [Memory](https://python.langchain.com/en/latest/modules/memory.html): LangChain 提供了 Memory 標準接口、 Memory 實現的集合以及使用內存的鏈/代理的示例。\n",
        "\n",
        "希望結束之後，大家可以配合其他 LLM 專案的練習，打造屬於自己的應用。\n",
        "\n",
        "官方教學連結：[Quick_start](https://langchain.readthedocs.io/en/latest/getting_started/getting_started.html)"
      ],
      "metadata": {
        "id": "1dKN8sU1zpQf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models: 透過語言模型，取得摘要、推理、生成能力\n",
        "\n",
        "LangChain 中最基本的元素 Model，底下我們可以透過簡單的例子示範如何操作。\n",
        "為此，讓我們假設一下正在打造一個服務，專門提供公司名稱，只要給我們公司描述，就給出建議的公司命名。\n",
        "\n",
        "為了可以實現這個目標，我們首先 import OpenAI 來執行，model-name 可以選擇 'text-davinci-003'，結束後，基本上你會覺得跟操作 ChatGPT 類似，如此一來你就完成了一個 LLM 應用程式。\n",
        "\n",
        "[OpenAI 模型](https://platform.openai.com/docs/models/gpt-3-5)\n",
        "\n",
        "[Langchain Model-LLM 連結](https://python.langchain.com/en/latest/modules/models/llms/integrations/openai.html)"
      ],
      "metadata": {
        "id": "GOKJlIOCz9y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "sttmJuYLzi-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(model_name=\"text-davinci-003\")"
      ],
      "metadata": {
        "id": "x_i2G2rr0QzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"What would be a good company name for a company that makes colorful shoes?\"\n",
        "print(llm(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq85cAD40S3t",
        "outputId": "8c19232d-3d44-4031-905e-b4776865549c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Bright Kicks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "恭喜你已經完成了第一個應用，可以透過 LangChain 呼叫 OpenAPI 回傳結果。"
      ],
      "metadata": {
        "id": "xlJ9xDWE0jz1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-- -- "
      ],
      "metadata": {
        "id": "K-an_dbh1Oh9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt: 替大型語言模型(LLM) 管理提示語(prompt)\n",
        "\n",
        "前面課程當中，呼叫 LLM 是非常好的開始，但這僅是第一步。通常在應用程式中呼叫 LLM 時，你不會直接將使用者撰寫的文字傳送至 LLM。相反的，你可能將使用者撰寫的文字進行組合，再傳送至 LLM 當中。\n",
        "\n",
        "例如，在前面的例子中，我們是要給定公司產品後，產生出合適的公司名稱。既然如此，我們可以把公司產品名稱作為參數，以此打造一個 Prompt。\n",
        "\n",
        "[Langchain Prompt 連結](https://python.langchain.com/en/latest/modules/prompts/prompt_templates/getting_started.html)"
      ],
      "metadata": {
        "id": "-yjlDkQ41arH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"product\"],\n",
        "    template=\"What is a good name for a company that makes {product}?\",\n",
        ")"
      ],
      "metadata": {
        "id": "G_HOi7YB1bbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt.format(product=\"colorful shoes\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MFakHQi1iZs",
        "outputId": "779aed1a-d0e4-41f8-fe0e-93fbb2a3f9fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is a good name for a company that makes colorful shoes?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-- --"
      ],
      "metadata": {
        "id": "7c-THT2l1nmH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chains: 結合 LLM 與 prompts 於多個步驟工作流中\n",
        "\n",
        "到目前為止，我們使用了 PromptTemplate 管理常用的提示語，也使用了 LLM 來獲得文字生成能力。但，這僅僅是分開而已，真正的應用是將兩者結合在一塊。\n",
        "\n",
        "在 LangChain 中，Chain 可以是由 llm 或是其他 Chain 連結接在一起。\n",
        "\n",
        "最核心的 Chain 是 LLMChain，它由 PromptTemplate 和 LLM 結合。\n",
        "\n",
        "讓我們延續前面了範例，這個環節中，我們建構一個 LLMChain，這個 Chain 會接受使用者輸入，並且使用 PromptTemplate 將其規格化，最後將規格化內容傳遞給 LLM。\n",
        "\n",
        "官方連結：[Chains](https://python.langchain.com/en/latest/modules/chains/getting_started.html)"
      ],
      "metadata": {
        "id": "0QLjKZNO1z3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0.9)\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"product\"],\n",
        "    template=\"What is a good name for a company that makes {product}?\",\n",
        ")"
      ],
      "metadata": {
        "id": "vWWih4B91jJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "現在，我們可以創建一個非常簡單的 Chain，將接收用戶輸入，使用其規格化提示，然後將其傳遞給 LLM："
      ],
      "metadata": {
        "id": "3UFxOGPh1_bC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm=llm, prompt=prompt)"
      ],
      "metadata": {
        "id": "GXXPXEFU19f4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(\"colorful shoes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JcMQbOD52Ean",
        "outputId": "d8f7835f-f58d-4526-bd0b-b918daab87f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nRainbow Footwear.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "GbihJ95O2aSE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agents: 讓 LLM 選擇要用的 tool 解決問題\n",
        "\n",
        "到目前為止，我們看到的應用都是是按照預定的順序運行的，特別是像 Chain 用法。\n",
        "\n",
        "然而，Agnet 不再如此，能夠使用 LLM 來確定要採取的動作及順序。動作可以是使用工具並觀察其輸出，也可以是返回結果給用戶。如果正確使用， Agent 可以非常強大。\n",
        "\n",
        "本課程中，我們將向展示如何通過最簡單 API 輕鬆使用 Agent。\n",
        "\n",
        "\n",
        "接觸 Agnets ，你應該會了解以下概念：\n",
        "\n",
        "* Tool：執行特定職責的功能。這可以是 Google搜索、查找資料庫、Python REPL、其他Chain 等等。\n",
        "* LLM：大型語言模型提供 Agents 決定要執行的動作以及順序。\n",
        "* Agent：要使用的代理。\n",
        "\n",
        "官方連結：[Agents](https://python.langchain.com/en/latest/modules/agents.html)\n",
        "\n",
        "點選以下連結知道更多 LangChain 提供的 [Agent](https://python.langchain.com/en/latest/modules/agents/getting_started.html)\n",
        "\n",
        "點選以下連結知道更多 LangChain 提供的 [Tools](https://python.langchain.com/en/latest/modules/agents/tools/getting_started.html)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cnTjOUN12czY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 在本例中，您還需要安裝SerpAPI Python套件。"
      ],
      "metadata": {
        "id": "i3BUbX2J2ywd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgZmFjuH2GET",
        "outputId": "f63ddad1-0dd8-4d19-c63f-3d5cfa5afbbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.4)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32019 sha256=8109085dab81e1fec314b4e4f3f2d3a7cfba2fbbc30989fe0dd08c1a12788d21\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/b2/c3/03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 設置 Serpapi 環境變數\n"
      ],
      "metadata": {
        "id": "CnaLwYuE25xE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"SERPAPI_API_KEY\"] = \"e661bc654720478b1f8d3d88f77723eb5f62f9aa9f771d8767ee0be103764baa\""
      ],
      "metadata": {
        "id": "UCiE8gCG2x5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 建立 Agent 詢問網路問題，例如：高雄天氣多少？相比台北溫度差多少？"
      ],
      "metadata": {
        "id": "mrr1k_Iy32ZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "# 第一步，讀取 llm 用來提供 Agent 做事情\n",
        "llm = OpenAI(temperature=0)\n",
        "\n",
        "# 第二步，讓我們添加些 tool 來提供動作，這邊選擇網路搜尋功能的 serpapi 以及計算數字用的 llm-math\n",
        "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
        "\n",
        "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "\n",
        "# Now let's test it out!\n",
        "agent.run(\"What was the high temperature in Taiwan yesterday in Kaohsiung? What is that number different with the high temperature in Taiwan yesterday in Taipei? To the end, display temperature in Celsius.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "JupT0QJm3zEC",
        "outputId": "3e06ad5e-478f-4bc8-9ac7-9e1fd3487d8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find out the temperatures in both Kaohsiung and Taipei\n",
            "Action: Search\n",
            "Action Input: \"High temperature in Taiwan yesterday Kaohsiung Taipei\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m84 °F · 84 °F · 84 °F ...\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to convert the temperatures to Celsius\n",
            "Action: Calculator\n",
            "Action Input: 84 °F\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 28.88888888888889\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: The high temperature in Kaohsiung yesterday was 28.88888888888889°C and the difference between Kaohsiung and Taipei was 0°C.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The high temperature in Kaohsiung yesterday was 28.88888888888889°C and the difference between Kaohsiung and Taipei was 0°C.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "L9ZCS0qa4M4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Memory: 賦予 Chains 與 Agents 記憶\n",
        "\n",
        "截自目前為止，我們介紹過的 Chain 以及 Agent 都是 stateless 的。但通常，你可能會希望添加 \"記憶\" 的概念在其中，以便他可以記住先前的互動資訊。最簡單的例子就是在設計聊天機器人時，你希望他會記住過往的對話，而不是像一個金魚腦，善用上下文來進行更流暢的對談。簡單來說，這將是一種短期記憶。在複雜情況下，你可能會需要 Chain 或是 Agent 隨著時間的推移記住重要的資訊，這將是一種長期記憶。\n",
        "\n",
        "在 LangChain 當中，為了賦予記憶的概念，專門建造了幾種 Chain。以下我們將示範 ConversationChain，預設情況下 ConversationChain 具有一種簡單的記憶類型，能夠記住「所有」先前聊天過程，並添加在傳遞的上下文中。請記得將 verbose 設置為 True，方便我們看到 Chain 運作過程\n",
        "\n",
        "官方連結：[Memory](https://python.langchain.com/en/latest/modules/memory/getting_started.html)"
      ],
      "metadata": {
        "id": "lWNaovnv4K2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import OpenAI, ConversationChain\n",
        "\n",
        "llm = OpenAI(temperature=0)\n",
        "conversation = ConversationChain(llm=llm, verbose=True)\n",
        "\n",
        "output = conversation.predict(input=\"Hi there!\")\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15NHP9es4DiZ",
        "outputId": "c303f445-6d0d-4cc7-8857-1988715632a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hi there!\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            " Hi there! It's nice to meet you. How can I help you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = conversation.predict(input=\"I am doing well! Currently, just have a conversation with you, an AI.\")\n",
        "print(output)"
      ],
      "metadata": {
        "id": "1bSj6gRy4Uvk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ff74735-bb64-4775-80aa-398fbd83be1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there!\n",
            "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
            "Human: I am doing well! Currently, just have a conversation with you, an AI.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            " That's great! It's nice to have a conversation with you too. What would you like to talk about?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ovOZVWlzwtT9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}